{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (0.24.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (1.6.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (3.3.4)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (1.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (8.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import Binarizer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Avocado Dataset.csv')\n",
    "df1 = pd.read_csv('Trail.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 11 -  Test drive the basic version of Apriori algorithms for Frequent Itemset Mining using the package / library support in the platform of your choice. Test it with various support and confidence measures and generate a time comparison for varied data set sizes. To do the performance comparison you may use benchmark datasets provided for FIM such as the FIMI workshop or other sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_function(df):\n",
    "    df_out = df.apply(lambda x: list(x.dropna().values), axis=1).tolist()\n",
    "    te = TransactionEncoder()\n",
    "    out = te.fit(df_out).transform(df_out)\n",
    "    final = pd.DataFrame(out, columns=te.columns_)\n",
    "    frequent_itemsets = apriori(final, min_support=0.1, max_len=3, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "    return frequent_itemsets, rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 12 - Test drive the basic version of FP Growth algorithms for Frequent Itemset Mining using the package / library support in the platform of your choice. Test it with various support and confidence measures and generate a time comparison for varied data set sizes. To do the performance comparison you may use benchmark datasets provided for FIM such as the FIMI workshop or other sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_growth_function(df):\n",
    "    df_out = df.apply(lambda x: list(x.dropna().values), axis=1).tolist()\n",
    "    te = TransactionEncoder()\n",
    "    out = te.fit(df_out).transform(df_out)\n",
    "    chess = pd.DataFrame(out, columns=te.columns_)\n",
    "    frequent_itemsets = fpgrowth(chess, min_support=0.1, max_len=3, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "    return frequent_itemsets, rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 14 - Mine frequent itemsets using FP-Growth* algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        support       itemsets\n",
      "0      1.000000          (109)\n",
      "1      1.000000           (67)\n",
      "2      1.000000           (16)\n",
      "3      1.000000           (34)\n",
      "4      1.000000           (37)\n",
      "...         ...            ...\n",
      "25905  0.319783   (44, 97, 72)\n",
      "25906  0.319783    (7, 44, 72)\n",
      "25907  0.308943  (44, 72, 115)\n",
      "25908  0.360434   (44, 82, 72)\n",
      "25909  0.325203   (44, 79, 72)\n",
      "\n",
      "[25910 rows x 2 columns]\n",
      "       antecedents consequents  antecedent support  consequent support  \\\n",
      "0            (109)        (67)            1.000000            1.000000   \n",
      "1             (67)       (109)            1.000000            1.000000   \n",
      "2             (16)        (67)            1.000000            1.000000   \n",
      "3             (67)        (16)            1.000000            1.000000   \n",
      "4             (16)       (109)            1.000000            1.000000   \n",
      "...            ...         ...                 ...                 ...   \n",
      "104276    (82, 72)        (44)            0.493225            0.791328   \n",
      "104277        (72)    (44, 82)            0.498645            0.785908   \n",
      "104278    (44, 72)        (79)            0.365854            0.940379   \n",
      "104279    (79, 72)        (44)            0.452575            0.791328   \n",
      "104280        (72)    (44, 79)            0.498645            0.737127   \n",
      "\n",
      "         support  confidence      lift  leverage  conviction  \n",
      "0       1.000000    1.000000  1.000000  0.000000         inf  \n",
      "1       1.000000    1.000000  1.000000  0.000000         inf  \n",
      "2       1.000000    1.000000  1.000000  0.000000         inf  \n",
      "3       1.000000    1.000000  1.000000  0.000000         inf  \n",
      "4       1.000000    1.000000  1.000000  0.000000         inf  \n",
      "...          ...         ...       ...       ...         ...  \n",
      "104276  0.360434    0.730769  0.923472 -0.029869    0.775068  \n",
      "104277  0.360434    0.722826  0.919734 -0.031455    0.772411  \n",
      "104278  0.325203    0.888889  0.945245 -0.018838    0.536585  \n",
      "104279  0.325203    0.718563  0.908047 -0.032932    0.741452  \n",
      "104280  0.325203    0.652174  0.884751 -0.042362    0.755759  \n",
      "\n",
      "[104281 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('connect.dat', header=None, sep='\\n')\n",
    "df = df[0].str.split(' ', expand=True)\n",
    "freq, rules = fp_growth_function(df)\n",
    "\n",
    "print(freq)\n",
    "print(rules)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0f70214c0dd213f07f54ee5d6e0ea644bdbba35113c9bfe8aaa0d1db03ad5dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
